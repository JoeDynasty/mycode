{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "video -> audio -> text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting SpeechRecognition\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/54/82f70dd84a89ce66b8431338a14fc8580e825e39ca5d79775859f2bcf895/SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8MB)\n",
      "\u001b[K     |████████████████████████████████| 32.8MB 19.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting moviepy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/54/01a8c4e35c75ca9724d19a7e4de9dc23f0ceb8769102c7de056113af61c3/moviepy-1.0.3.tar.gz (388kB)\n",
      "\u001b[K     |████████████████████████████████| 389kB 54.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.26.0 (from SpeechRecognition)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/f4/274d1dbe96b41cf4e0efb70cbced278ffd61b5c7bb70338b62af94ccb25b/requests-2.28.2-py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 35.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator<5.0,>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from moviepy) (4.4.0)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /opt/conda/lib/python3.7/site-packages (from moviepy) (4.32.2)\n",
      "Collecting proglog<=1.0.0 (from moviepy)\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/f5/cab5cf6a540c31f5099043de0ae43990fd9cf66f75ecb5e9f254a4e4d4ee/proglog-0.1.10-py3-none-any.whl\n",
      "Collecting numpy>=1.17.3 (from moviepy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/ad/ff3b21ebfe79a4d25b4a4f8e5cf9fd44a204adb6b33c09010f566f51027a/numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7MB 52.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: imageio<3.0,>=2.5 in /opt/conda/lib/python3.7/site-packages (from moviepy) (2.5.0)\n",
      "Collecting imageio_ffmpeg>=0.2.0 (from moviepy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/3f/fc9a0345a0ef2d9596c3d3d9549ac72377ea97c289abcf3c96f0821c3072/imageio_ffmpeg-0.4.8-py3-none-manylinux2010_x86_64.whl (26.9MB)\n",
      "\u001b[K     |████████████████████████████████| 26.9MB 45.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.26.0->SpeechRecognition) (1.25.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from imageio<3.0,>=2.5->moviepy) (6.1.0)\n",
      "Building wheels for collected packages: moviepy\n",
      "  Building wheel for moviepy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for moviepy: filename=moviepy-1.0.3-cp37-none-any.whl size=110729 sha256=000fc3f58a1a5c132ea4bac082a6de507b368aba3915ab281519658ab38eb3e5\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/e0/fe/1c/f4e6dca9e828d4b979c04e461d7fcc5b8e7bd35f947e665b65\n",
      "Successfully built moviepy\n",
      "\u001b[31mERROR: tensorboard 2.1.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.16.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: requests, SpeechRecognition, proglog, numpy, imageio-ffmpeg, moviepy\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: numpy 1.16.0\n",
      "    Uninstalling numpy-1.16.0:\n",
      "      Successfully uninstalled numpy-1.16.0\n",
      "Successfully installed SpeechRecognition-3.9.0 imageio-ffmpeg-0.4.8 moviepy-1.0.3 numpy-1.21.6 proglog-0.1.10 requests-2.28.2\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import moviepy.editor as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:  30%|███       | 305/1014 [00:00<00:00, 3046.75it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in converted.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "clip = mp.VideoFileClip(r\"Panda Express.mp4\") #upload video clip\n",
    "clip.audio.write_audiofile(r\"converted.wav\") #strips out the audio, r in front means read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = sr.AudioFile(\"converted.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.95029861,\n",
      "                           'transcript': 'Panda Express approaches restaurant '\n",
      "                                         \"any better can't describe any \"\n",
      "                                         'better'},\n",
      "                       {   'transcript': 'Panda Express approaches restaurant '\n",
      "                                         \"any better I Can't Describe any \"\n",
      "                                         'better'},\n",
      "                       {   'transcript': 'Panda Express approaches restaurant '\n",
      "                                         \"any better if you wanted can't \"\n",
      "                                         'describe any better'},\n",
      "                       {   'transcript': 'Panda Express approaches an actual '\n",
      "                                         \"Chinese restaurant any better can't \"\n",
      "                                         'describe any better'},\n",
      "                       {   'transcript': 'Panda Express approaches restaurant '\n",
      "                                         \"don't be any better if you wanted \"\n",
      "                                         \"can't describe any better\"}],\n",
      "    'final': True}\n"
     ]
    }
   ],
   "source": [
    "#recognize audio file\n",
    "with audio as source:\n",
    "    audio_file = r.record(source)\n",
    "result = r.recognize_google(audio_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready!\n"
     ]
    }
   ],
   "source": [
    "with open('recognized.txt', mode=\"w\") as file:\n",
    "    file.write(\"This is the recognized speech in the video: \")\n",
    "    file.write(\"\\n\")\n",
    "    file.write(result)\n",
    "    print(\"ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-_ejmpne3\n",
      "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-_ejmpne3\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (1.21.6)\n",
      "Collecting torch (from openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/86/77a9eddbf46f1bca2468d16a401911f58917f95b63402d6a7a4522521e5d/torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5MB)\n",
      "\u001b[K     |████████████████████████████████| 887.5MB 38kB/s s eta 0:00:01    |█▏                              | 30.9MB 22.9MB/s eta 0:00:38     |██▍                             | 64.9MB 60.8MB/s eta 0:00:14     |██▉                             | 79.5MB 60.8MB/s eta 0:00:14     |███▎                            | 91.2MB 60.8MB/s eta 0:00:14     |███▊                            | 102.5MB 60.8MB/s eta 0:00:13     |█████████████████▊              | 491.9MB 43.6MB/s eta 0:00:10     |████████████████████████████▏   | 782.2MB 48.3MB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (4.32.2)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (8.0.2)\n",
      "Collecting transformers>=4.19.0 (from openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/1a/ef470ac1ff879b823c718ddc08c5b33ab4e68100b565a7037f8bf3aa98de/transformers-4.26.0-py3-none-any.whl (6.3MB)\n",
      "\u001b[K     |████████████████████████████████| 6.3MB 38.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ffmpeg-python==0.2.0 (from openai-whisper==20230124)\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/0c/56be52741f75bad4dc6555991fabd2e07b432d333da82c11ad701123888a/ffmpeg_python-0.2.0-py3-none-any.whl\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/30/66d4347d6e864334da5bb1c7571305e501dcb11b9155971421bb7bb5315f/nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1MB)\n",
      "\u001b[K     |████████████████████████████████| 557.1MB 72kB/s  eta 0:00:011     |████████▊                       | 151.3MB 78.4MB/s eta 0:00:06     |█████████████████▋              | 307.0MB 75.2MB/s eta 0:00:04MB/s eta 0:00:02     |███████████████████████████████▍| 547.4MB 70.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->openai-whisper==20230124) (4.4.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/fdeb62b5437996e841d83d7d2714ca75b886547ee8017ee2fe6ea409d983/nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1MB)\n",
      "\u001b[K     |████████████████████████████████| 317.1MB 216kB/s  eta 0:00:01                              | 768kB 31.8MB/s eta 0:00:10    | 8.6MB 31.8MB/s eta 0:00:10     |███████████████████████████████ | 308.0MB 81.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/92/89cf558b514125d2ebd8344dd2f0533404b416486ff681d5434a5832a019/nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849kB)\n",
      "\u001b[K     |████████████████████████████████| 849kB 60.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" (from torch->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/25/922c5996aada6611b79b53985af7999fc629aee1d5d001b6a22431e18fec/nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0MB)\n",
      "\u001b[K     |████████████████████████████████| 21.0MB 42.0MB/s eta 0:00:01                     | 266kB 42.0MB/s eta 0:00:01  | 829kB 42.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "  Downloading https://files.pythonhosted.org/packages/14/4c/b201d0292ca4e0950f0741212935eac9996f69cd66b92a3587e594999163/filelock-3.9.0-py3-none-any.whl\n",
      "Collecting packaging>=20.0 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/35/a31aed2993e398f6b09a790a181a7927eb14610ee8bbf02dc14d31677f1c/packaging-23.0-py3-none-any.whl (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 37.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (1.3.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/d9/af2821b5934ed871f716eb65fb3bd43e7bc70b99191ec08f20cfd642d0a1/tokenizers-0.13.2.tar.gz (359kB)\n",
      "\u001b[K     |████████████████████████████████| 368kB 58.8MB/s eta 0:00:01�████▏            | 215kB 58.8MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting regex!=2019.12.17 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/f2/20be658beb9ebef677550be562eae86c5433119b4b2fdb67035e9a841b0f/regex-2022.10.31-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (676kB)\n",
      "\u001b[K     |████████████████████████████████| 686kB 48.0MB/s eta 0:00:010:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (5.1.2)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers>=4.19.0->openai-whisper==20230124)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/0b/e4c1165bb954036551e61e1d7858e3293347f360d8f84854092f3ad38446/huggingface_hub-0.11.1-py3-none-any.whl (182kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 48.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.18.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch->openai-whisper==20230124) (41.0.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\"->torch->openai-whisper==20230124) (0.33.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.19.0->openai-whisper==20230124) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.25.3)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (PEP 517) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python /opt/conda/lib/python3.7/site-packages/pip/_vendor/pep517/_in_process.py build_wheel /tmp/tmpy8wo75nh\n",
      "       cwd: /tmp/pip-install-rbwnzzz6/tokenizers\n",
      "  Complete output (51 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-cpython-37\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers\n",
      "  copying py_src/tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/models\n",
      "  copying py_src/tokenizers/models/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/models\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/decoders\n",
      "  copying py_src/tokenizers/decoders/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/decoders\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/normalizers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/normalizers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/pre_tokenizers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/processors\n",
      "  copying py_src/tokenizers/processors/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/processors\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/trainers\n",
      "  copying py_src/tokenizers/trainers/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/trainers\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_bpe.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/sentencepiece_unigram.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/base_tokenizer.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/char_level_bpe.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/byte_level_bpe.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/bert_wordpiece.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  copying py_src/tokenizers/implementations/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/implementations\n",
      "  creating build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  copying py_src/tokenizers/tools/visualizer.py -> build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  copying py_src/tokenizers/tools/__init__.py -> build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  copying py_src/tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers\n",
      "  copying py_src/tokenizers/models/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/models\n",
      "  copying py_src/tokenizers/decoders/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/decoders\n",
      "  copying py_src/tokenizers/normalizers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/normalizers\n",
      "  copying py_src/tokenizers/pre_tokenizers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/pre_tokenizers\n",
      "  copying py_src/tokenizers/processors/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/processors\n",
      "  copying py_src/tokenizers/trainers/__init__.pyi -> build/lib.linux-x86_64-cpython-37/tokenizers/trainers\n",
      "  copying py_src/tokenizers/tools/visualizer-styles.css -> build/lib.linux-x86_64-cpython-37/tokenizers/tools\n",
      "  running build_ext\n",
      "  running build_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for tokenizers\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-rbwnzzz6/tokenizers/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-rbwnzzz6/tokenizers/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' clean --all\n",
      "       cwd: /tmp/pip-install-rbwnzzz6/tokenizers\n",
      "  Complete output (17 lines):\n",
      "  running clean\n",
      "  removing 'build/lib.linux-x86_64-cpython-37' (and everything under it)\n",
      "  'build/bdist.linux-x86_64' does not exist -- can't clean it\n",
      "  'build/scripts-3.7' does not exist -- can't clean it\n",
      "  removing 'build'\n",
      "  running clean_rust\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed cleaning build dir for tokenizers\u001b[0m\n",
      "Failed to build tokenizers\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230124-cp37-none-any.whl size=1179323 sha256=8f193d8b8e0d64e51ceae6272b58865341e49f9c0012f46d62b214ce990f0e7a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0agr00zw/wheels/f7/a2/f4/4fcc21ffab3471a668533ce9a7fcf9dc13ec2540ed6cec230c\n",
      "Successfully built openai-whisper\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers which use PEP 517 and cannot be installed directly\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting pytube\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/61/d53566d4634f3f27b60867f054330b3ec1d22d399e20a9708a1a00471987/pytube-12.1.2-py3-none-any.whl (57kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 19.9MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-12.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: whisper: not found\n"
     ]
    }
   ],
   "source": [
    "!whisper \"./Panda Express.mp4\" --model medium --language English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/bd/2410905c76ee14c62baf69e3f4aa780226c1bbfc9485731ad018e35b0cb5/pip-22.3.1-py3-none-any.whl (2.1MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1MB 20.4MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.2.1\n",
      "    Uninstalling pip-19.2.1:\n",
      "      Successfully uninstalled pip-19.2.1\n",
      "Successfully installed pip-22.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-5k68fbkb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-5k68fbkb\n",
      "  Resolved https://github.com/openai/whisper.git to commit 4e635c66441dfae3c6c72365f802293afffca3ef\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (1.21.6)\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (4.32.2)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.7/site-packages (from openai-whisper==20230124) (8.0.2)\n",
      "Collecting transformers>=4.19.0\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m157.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
      "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.18.2)\n",
      "Collecting packaging>=20.0\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m162.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.1/757.1 kB\u001b[0m \u001b[31m245.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m224.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (5.1.2)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.28.2)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.19.0->openai-whisper==20230124) (1.3.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m200.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->openai-whisper==20230124) (4.4.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230124) (0.33.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->openai-whisper==20230124) (41.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers>=4.19.0->openai-whisper==20230124) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.25.3)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179325 sha256=483d01b7f79e67bb9635fc2f4fc17cff1a836697323b020f57db815d698fc681\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-whx9qplh/wheels/16/15/89/1c7bb31bd0006793a95549d04785121a8a36daad9158e1e43a\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: tokenizers, regex, packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, filelock, ffmpeg-python, nvidia-cudnn-cu11, torch, huggingface-hub, transformers, openai-whisper\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 19.0\n",
      "    Uninstalling packaging-19.0:\n",
      "      Successfully uninstalled packaging-19.0\n",
      "Successfully installed ffmpeg-python-0.2.0 filelock-3.9.0 huggingface-hub-0.11.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 openai-whisper-20230124 packaging-23.0 regex-2022.10.31 tokenizers-0.13.2 torch-1.13.1 transformers-4.26.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pytube in /opt/conda/lib/python3.7/site-packages (12.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/whisper\", line 5, in <module>\n",
      "    from whisper.transcribe import cli\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/whisper/__init__.py\", line 12, in <module>\n",
      "    from .decoding import DecodingOptions, DecodingResult, decode, detect_language\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/whisper/decoding.py\", line 514\n",
      "    if prefix := self.options.prefix:\n",
      "               ^\n",
      "SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "!whisper \"./Panda Express.mp4\" --model medium --language English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
